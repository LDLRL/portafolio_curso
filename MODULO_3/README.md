# ğŸ“Š MÃ³dulo 3 â€“ ObtenciÃ³n y PreparaciÃ³n de Datos

Este mÃ³dulo se enfocÃ³ en adquirir habilidades prÃ¡cticas para preparar datos reales utilizando las librerÃ­as **NumPy** y **Pandas**. A lo largo de seis lecciones y un proyecto final, se implementÃ³ un flujo completo de trabajo para obtener, limpiar, transformar, analizar y exportar datos provenientes de mÃºltiples fuentes.

---

## ğŸ¯ Objetivo del MÃ³dulo

El objetivo principal fue desarrollar un proceso automatizado y eficiente para la preparaciÃ³n de datos, desde su generaciÃ³n o carga hasta su exportaciÃ³n final, asegurando la calidad y consistencia para su uso posterior.

---

## ğŸ“š Contenido del MÃ³dulo

### ğŸ”¹ LecciÃ³n 1 â€“ Uso de NumPy

- GeneraciÃ³n de datos ficticios con arrays de NumPy: ID de clientes, montos de compra y edades.
- AplicaciÃ³n de operaciones estadÃ­sticas como suma, media y conteo.
- Almacenamiento de los arrays en archivos `.npy`.

**ReflexiÃ³n:** NumPy demostrÃ³ ser muy Ãºtil por su rapidez y eficiencia al trabajar con grandes volÃºmenes de datos numÃ©ricos.

---

### ğŸ”¹ LecciÃ³n 2 â€“ IntroducciÃ³n a Pandas

- ConversiÃ³n de arrays a un DataFrame.
- ExploraciÃ³n inicial con mÃ©todos como `head()`, `describe()` y filtros condicionales.
- ExportaciÃ³n del DataFrame preliminar en formato `.csv`.

**ReflexiÃ³n:** Pandas facilitÃ³ mucho el manejo de datos tabulares, haciendo posible analizar y preparar rÃ¡pidamente la informaciÃ³n.

---

### ğŸ”¹ LecciÃ³n 3 â€“ IntegraciÃ³n de MÃºltiples Fuentes

- Carga de datos desde CSV y Excel.
- ExtracciÃ³n de una tabla HTML desde una pÃ¡gina web (Wikipedia).
- UniÃ³n de los diferentes DataFrames usando `merge()` y `concat()`.

**ReflexiÃ³n:** Fue desafiante integrar diferentes formatos, pero se aprendiÃ³ a unificar datos dispersos en un solo conjunto coherente.

---

### ğŸ”¹ LecciÃ³n 4 â€“ Limpieza de Datos

- IdentificaciÃ³n y tratamiento de valores nulos con imputaciÃ³n basada en la media.
- DetecciÃ³n y eliminaciÃ³n de outliers con el mÃ©todo del rango intercuartÃ­lico (IQR).
- ExportaciÃ³n del DataFrame limpio.

**ReflexiÃ³n:** Se comprendiÃ³ la importancia de limpiar los datos antes de analizarlos. Aunque se usÃ³ la media para imputar valores faltantes, en casos con mucha dispersiÃ³n serÃ­a mÃ¡s conveniente usar la mediana.

---

### ğŸ”¹ LecciÃ³n 5 â€“ Data Wrangling

- EliminaciÃ³n de duplicados.
- ConversiÃ³n de tipos de datos.
- CreaciÃ³n de nuevas columnas (por ejemplo, segmentaciÃ³n por edad y categorÃ­as de monto).
- AplicaciÃ³n de funciones lambda y categorizaciÃ³n personalizada.

**ReflexiÃ³n:** Estas tÃ©cnicas ayudaron a enriquecer y transformar los datos para que sean mÃ¡s Ãºtiles en anÃ¡lisis posteriores.

---

### ğŸ”¹ LecciÃ³n 6 â€“ Agrupamiento y Pivoteo

- AgrupaciÃ³n con `groupby()` para obtener estadÃ­sticas resumidas.
- ReestructuraciÃ³n de datos con `pivot_table()` y `melt()`.
- CombinaciÃ³n final de fuentes y exportaciÃ³n del dataset a formatos CSV y Excel.

**ReflexiÃ³n:** Estas herramientas permitieron generar resÃºmenes Ãºtiles y organizar los datos en formatos que facilitan el anÃ¡lisis visual y tabular.

---

## ğŸ› ï¸ Proyecto Final â€“ PreparaciÃ³n Integral del Dataset

### ğŸ’¼ Contexto

SimulaciÃ³n de una situaciÃ³n real de una empresa de e-commerce que necesita preparar un dataset para anÃ¡lisis. Se trabajÃ³ con datos generados y fuentes externas (Excel y web), aplicando limpieza y transformaciÃ³n para obtener un resultado confiable.

### ğŸ”§ Pasos Realizados

1. GeneraciÃ³n de datos con NumPy.
2. ExploraciÃ³n y anÃ¡lisis inicial con Pandas.
3. Carga de datos desde CSV, Excel y web.
4. Limpieza de valores nulos y outliers.
5. Wrangling: creaciÃ³n de columnas, tipos de datos y transformaciones.
6. Agrupamiento y pivoteo para organizaciÃ³n final del dataset.
7. ExportaciÃ³n a archivos `.csv` y `.xlsx`.

### ğŸ“ Archivos Entregables del proyecto final 

- `modulo3_proyecto.ipynb`: Notebook con todo el cÃ³digo y explicaciones.
- `dataset_final.csv` y `dataset_final.xlsx`: Dataset estructurado y listo para anÃ¡lisis.
- `documento_resumen.md`: Documento que explica cada etapa del proceso.
- `ejercicios de clase de cada lecciÃ³n: Notebooks con todo el cÃ³digo y explicaciones.

---

## ğŸ§  Habilidades Desarrolladas

- Lectura e integraciÃ³n de datos de diferentes fuentes.
- Limpieza y preparaciÃ³n de datos con NumPy y Pandas.
- Manejo de valores nulos, duplicados y outliers.
- Transformaciones avanzadas y creaciÃ³n de nuevas variables.
- AgrupaciÃ³n y pivoteo de datos para estructurar reportes.
- ExportaciÃ³n de datasets en formatos estÃ¡ndar.

---

## âœ… Conclusiones

Este mÃ³dulo permitiÃ³ adquirir herramientas clave para el trabajo prÃ¡ctico con datos. A travÃ©s del proyecto final se pudo integrar todos los conocimientos en un flujo de trabajo completo. Se destaca la importancia de realizar limpieza y estructuraciÃ³n adecuada antes de cualquier anÃ¡lisis. AdemÃ¡s, se valorÃ³ la potencia de Pandas y NumPy como aliados esenciales en la preparaciÃ³n de datos en entornos reales.

---

## ğŸ“Œ Requisitos TÃ©cnicos

- Python 3
- LibrerÃ­as: `numpy`, `pandas`
- Google Colab 
- ConexiÃ³n a internet para acceder a la fuente web

---


